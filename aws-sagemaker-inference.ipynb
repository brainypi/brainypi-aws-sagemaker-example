{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cae6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "\n",
    "AWS_REGION = 'ap-south-1'\n",
    "\n",
    "# Create an IAM client to interact with IAM\n",
    "iam_client = boto3.client('iam', region_name=AWS_REGION)\n",
    "role_name = 'BrainyPi_sagemaker_tutorial'\n",
    "\n",
    "policy = {\n",
    "    'Statement': [\n",
    "        {\n",
    "            'Action': 'sts:AssumeRole',\n",
    "            'Effect': 'Allow',\n",
    "            'Principal': {'Service': 'sagemaker.amazonaws.com'},\n",
    "        }],\n",
    "     'Version': '2012-10-17'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fb2952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "new_role = iam_client.create_role(\n",
    "    AssumeRolePolicyDocument=json.dumps(policy),\n",
    "    Path='/',\n",
    "    RoleName=role_name\n",
    ")\n",
    "\n",
    "role_arn = new_role['Role']['Arn']\n",
    "\n",
    "iam_client.attach_role_policy(\n",
    "    RoleName=role_name,\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonSageMakerFullAccess'\n",
    ")\n",
    "\n",
    "iam_client.attach_role_policy(\n",
    "    RoleName=role_name,\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess'\n",
    ");\n",
    "\n",
    "print(\"Done! Role created. Role ARN: %s\" % role_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c8437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an S3 client\n",
    "s3_client = boto3.client('s3', region_name=AWS_REGION)\n",
    "\n",
    "# Name buckets\n",
    "bucket='sagemakertutorial'\n",
    "\n",
    "# Check if bucket exists\n",
    "if boto3.resource('s3').Bucket(bucket) not in boto3.resource('s3').buckets.all():\n",
    "    s3_client.create_bucket(\n",
    "        Bucket=bucket,\n",
    "        CreateBucketConfiguration={\n",
    "            'LocationConstraint': AWS_REGION\n",
    "        }\n",
    "    )\n",
    "else:\n",
    "    print(f'Bucket {bucket} already exists. No action needed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33feff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_zip_filename = './coco_ssd_mobilenet_v1_1.0.zip'\n",
    "!curl http://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip \\\n",
    "    --output {model_zip_filename}\n",
    "\n",
    "# Extract model from zip file\n",
    "!unzip -u {model_zip_filename}\n",
    "\n",
    "model_filename = 'detect.tflite'\n",
    "model_name = model_filename.split('.')[0]\n",
    "\n",
    "# Compress model into .tar.gz so SageMaker Neo can use it\n",
    "model_tar = model_name + '.tar.gz'\n",
    "!tar -czf {model_tar} {model_filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df7ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model        \n",
    "s3_client.upload_file(Filename=model_tar, Bucket=bucket, Key=model_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b90947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_location = f's3://{bucket}/{model_tar}'\n",
    "s3_output_location = f's3://{bucket}/output'\n",
    "\n",
    "framework = 'tflite'\n",
    "data_shape = '{\"normalized_input_image_tensor\":[1, 300, 300, 3]}'\n",
    "target_device = 'rk3399'\n",
    "# Create a SageMaker client so you can submit a compilation job\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=AWS_REGION)\n",
    "\n",
    "# Give your compilation job a name\n",
    "compilation_job_name = 'brainypiSagemakerTutorial4'\n",
    "print(f'Compilation job for {compilation_job_name} started')\n",
    "\n",
    "response = sagemaker_client.create_compilation_job(\n",
    "    CompilationJobName=compilation_job_name,\n",
    "    RoleArn=role_arn,\n",
    "    InputConfig={\n",
    "        'S3Uri': s3_input_location,\n",
    "        'DataInputConfig': data_shape,\n",
    "        'Framework': framework.upper()\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': s3_output_location,\n",
    "        'TargetPlatform': {\n",
    "            'Arch': \"ARM64\",\n",
    "            'Os': \"LINUX\"\n",
    "        } \n",
    "    },\n",
    "    StoppingCondition={\n",
    "        'MaxRuntimeInSeconds': 900\n",
    "    }\n",
    ")\n",
    "\n",
    "# Optional - Poll every 30 sec to check completion status\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    response = sagemaker_client.describe_compilation_job(CompilationJobName=compilation_job_name)\n",
    "    if response['CompilationJobStatus'] == 'COMPLETED':\n",
    "        break\n",
    "    elif response['CompilationJobStatus'] == 'FAILED':\n",
    "        raise RuntimeError('Compilation failed')\n",
    "    print('Compiling ...')\n",
    "    time.sleep(30)\n",
    "print('Done!')\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5021250d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install numpy pillow matplotlib \n",
    "\n",
    "!pip install https://neo-ai-dlr-release.s3-us-west-2.amazonaws.com/v1.10.0/rk3399/dlr-1.10.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e005638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download compiled model locally to edge device\n",
    "object_path = f'output/{model_name}-LINUX_ARM64.tar.gz'\n",
    "neo_compiled_model = f'compiled-{model_name}.tar.gz'\n",
    "s3_client.download_file(bucket, object_path, neo_compiled_model)\n",
    "\n",
    "# Extract model from .tar.gz so DLR can use it\n",
    "!mkdir ./dlr_model # make a directory to store your model (optional)\n",
    "!tar -xzvf ./compiled-detect.tar.gz --directory ./dlr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a927c4a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Download an image for model to make a prediction\n",
    "input_image_filename = './input_image.jpg'\n",
    "!curl https://farm9.staticflickr.com/8463/8132484846_8ce4da18ba_z.jpg --output {input_image_filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3606a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlr\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from dlr.counter.phone_home import PhoneHome\n",
    "\n",
    "device = 'cpu'\n",
    "model = dlr.DLRModel('./dlr_model', device)\n",
    "PhoneHome.disable_feature()\n",
    "\n",
    "classLabels = []\n",
    "filename = './labelmap.txt'\n",
    "with open(filename, 'rt') as spt:\n",
    "    classLabels = spt.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "inputImage = cv2.imread(\"./input_image.jpg\")\n",
    "\n",
    "# Format image so model can make predictions\n",
    "#resized_image = image.resize((300, 300))\n",
    "resized_image = cv2.resize(inputImage, (300, 300), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# Model is quantized, so convert the image to uint8\n",
    "x = np.array(resized_image).astype('uint8')\n",
    "out = model.run(x)\n",
    "\n",
    "detection_boxes = np.squeeze(out[0])\n",
    "detection_classes = np.squeeze(out[1])\n",
    "detection_scores = np.squeeze(out[2]) \n",
    "num_detections = np.squeeze(out[3])\n",
    "\n",
    "# Loop over the detections\n",
    "for i in range(num_detections):\n",
    "    confidence = detection_scores[i]\n",
    "    if confidence > 0.6:  # You can adjust the confidence threshold as needed\n",
    "        class_id = int(detection_classes[i])\n",
    "        class_name = classLabels[class_id + 1]\n",
    "        box = detection_boxes[i] * np.array([inputImage.shape[1], inputImage.shape[0], inputImage.shape[1], inputImage.shape[0]])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "        cv2.rectangle(inputImage, (startX, startY), (endX, endY), (255, 0, 0), 2)\n",
    "        y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "        text = \"{}: {:.2f}%\".format(class_name, (confidence * 100))\n",
    "        cv2.putText(inputImage, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "# Display the image with bounding boxes\n",
    "cv2.imshow(\"Image with Bounding Boxes\", inputImage)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
